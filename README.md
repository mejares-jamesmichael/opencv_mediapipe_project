# OpenCV MediaPipe Real-Time Gesture Recognition

A real-time computer vision project that uses OpenCV and Google's MediaPipe framework to detect hand gestures, count fingers, and recognize facial expressions from a live camera feed.

## ğŸš€ Features

- **Real-time finger counting**: Detects and counts raised fingers from both hands
- **Facial expression recognition**: Detects smiles and tongue-out expressions
- **Interactive visual feedback**: Displays images/GIFs when specific expressions are detected
- **Multi-hand support**: Can track up to 2 hands simultaneously
- **Visual landmark overlay**: Shows hand and face landmarks in real-time

## ğŸ“‹ Prerequisites

- Python 3.7 or higher
- Camera access (webcam or built-in camera)

## ğŸ› ï¸ Installation

1. Clone or download this repository
2. Create and activate a virtual environment (recommended):
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```
3. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸš€ Usage

1. Make sure your camera is connected and accessible
2. Run the main script:
   ```bash
   python main.py
   ```
3. Press 'q' to quit the application

## ğŸ¯ How It Works

### Finger Counting
- The system identifies hand landmarks using MediaPipe's hand tracking
- Counts raised fingers based on landmark positions:
  - Thumb: compared by X-axis position (relative to wrist)
  - Other fingers: compared by Y-axis position (relative to knuckles)
- Displays total finger count in real-time

### Facial Expression Detection
- **Smile Detection**: Analyzes the position of mouth corners relative to upper lip
- **Tongue Detection**: Measures the distance between upper and lower lips

### Visual Feedback
- When a smile is detected, an image (`media/perfect_cell.jpg`) is displayed
- When tongue-out expression is detected, an animated GIF (`media/tongue.gif`) plays in the corner

## ğŸ“ Project Structure

```
opencv_mediapipe_project/
â”œâ”€â”€ main.py                 # Main application code
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ AGENTS.md              # Agent configuration
â””â”€â”€ media/
    â”œâ”€â”€ perfect_cell.jpg   # Image displayed when smiling
    â””â”€â”€ tongue.gif         # Animation displayed when tongue is out
```

## ğŸ”§ Configuration

You can adjust these parameters in `main.py`:

- `max_num_hands`: Maximum number of hands to detect (default: 2)
- `min_detection_confidence`: Minimum confidence for hand detection (default: 0.7)
- `max_num_faces`: Maximum number of faces to detect (default: 1)
- `min_detection_confidence`: Minimum confidence for face detection (default: 0.7)

## ğŸ“¦ Dependencies

This project uses:

- **OpenCV**: For camera capture and image processing
- **MediaPipe**: For hand and face landmark detection
- **imageio**: For GIF handling
- **NumPy**: For numerical operations

For a complete list, see `requirements.txt`.

## âš ï¸ Known Issues & Limitations

- Performance may vary based on hardware capabilities
- Lighting conditions can affect detection accuracy
- May require calibration for different face shapes
- GIF animation may be choppy on lower-end systems

## ğŸ“š Learn More

- [MediaPipe Documentation](https://google.github.io/mediapipe/)
- [OpenCV Documentation](https://docs.opencv.org/)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ™ Acknowledgements

- Google's MediaPipe team for providing the landmark detection models
- OpenCV community for computer vision tools
- [imageio](https://imageio.github.io/) for GIF support